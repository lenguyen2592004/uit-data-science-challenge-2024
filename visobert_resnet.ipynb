{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "CAfBEaleFMqR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9663692,
          "sourceType": "datasetVersion",
          "datasetId": 5879213
        }
      ],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import librosa\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "hC7jAEClF1XP",
        "execution": {
          "iopub.status.busy": "2024-10-22T16:55:49.904476Z",
          "iopub.execute_input": "2024-10-22T16:55:49.904782Z",
          "iopub.status.idle": "2024-10-22T16:55:55.244932Z",
          "shell.execute_reply.started": "2024-10-22T16:55:49.904748Z",
          "shell.execute_reply": "2024-10-22T16:55:55.243961Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Another version\n"
      ],
      "metadata": {
        "id": "ctnXhJ28FKVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from transformers import AutoModel, AutoTokenizer, get_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import AdamW,Adam\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from time import perf_counter\n",
        "from PIL import Image\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "C08RsK2WIuj3",
        "execution": {
          "iopub.status.busy": "2024-10-22T16:55:55.246627Z",
          "iopub.execute_input": "2024-10-22T16:55:55.247068Z",
          "iopub.status.idle": "2024-10-22T16:55:57.413278Z",
          "shell.execute_reply.started": "2024-10-22T16:55:55.247016Z",
          "shell.execute_reply": "2024-10-22T16:55:57.412338Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seeds for repeatability\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def set_seed(seed_val):\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "seed_val = 0\n",
        "set_seed(seed_val)"
      ],
      "metadata": {
        "id": "qxOdLLhTIxmI",
        "execution": {
          "iopub.status.busy": "2024-10-22T16:55:57.414865Z",
          "iopub.execute_input": "2024-10-22T16:55:57.415339Z",
          "iopub.status.idle": "2024-10-22T16:55:57.426668Z",
          "shell.execute_reply.started": "2024-10-22T16:55:57.415304Z",
          "shell.execute_reply": "2024-10-22T16:55:57.425703Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/kaggle/input/dsc2024/train.csv')\n",
        "len(df)"
      ],
      "metadata": {
        "id": "NXlRN68ApfW-",
        "execution": {
          "iopub.status.busy": "2024-10-22T16:55:57.429152Z",
          "iopub.execute_input": "2024-10-22T16:55:57.429791Z",
          "iopub.status.idle": "2024-10-22T16:55:57.621151Z",
          "shell.execute_reply.started": "2024-10-22T16:55:57.429751Z",
          "shell.execute_reply": "2024-10-22T16:55:57.620203Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test=pd.read_csv('/kaggle/input/dsc2024/test.csv')\n",
        "len(df_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T16:55:57.622475Z",
          "iopub.execute_input": "2024-10-22T16:55:57.623166Z",
          "iopub.status.idle": "2024-10-22T16:55:57.651107Z",
          "shell.execute_reply.started": "2024-10-22T16:55:57.623118Z",
          "shell.execute_reply": "2024-10-22T16:55:57.650278Z"
        },
        "trusted": true,
        "id": "NLOfEd5rjmqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# split train and dev\n",
        "df_train, df_dev = train_test_split(df, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "hAl91U8bFutY",
        "execution": {
          "iopub.status.busy": "2024-10-22T16:55:57.652045Z",
          "iopub.execute_input": "2024-10-22T16:55:57.652339Z",
          "iopub.status.idle": "2024-10-22T16:55:57.675630Z",
          "shell.execute_reply.started": "2024-10-22T16:55:57.652303Z",
          "shell.execute_reply": "2024-10-22T16:55:57.674873Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_train))\n",
        "print(len(df_dev))\n",
        "print(len(df_test))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T16:55:57.676548Z",
          "iopub.execute_input": "2024-10-22T16:55:57.676882Z",
          "iopub.status.idle": "2024-10-22T16:55:57.685163Z",
          "shell.execute_reply.started": "2024-10-22T16:55:57.676849Z",
          "shell.execute_reply": "2024-10-22T16:55:57.684065Z"
        },
        "trusted": true,
        "id": "lc6EKJJUjmqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_TRAIN_FOLDER='/kaggle/input/dsc2024/training-images/train-images/'\n",
        "IMAGE_TEST_FOLDER='/kaggle/input/dsc2024/public-test-images/dev-images/'"
      ],
      "metadata": {
        "id": "DXNL5B4iFw8c",
        "execution": {
          "iopub.status.busy": "2024-10-22T16:55:57.686822Z",
          "iopub.execute_input": "2024-10-22T16:55:57.687169Z",
          "iopub.status.idle": "2024-10-22T16:55:57.694615Z",
          "shell.execute_reply.started": "2024-10-22T16:55:57.687129Z",
          "shell.execute_reply": "2024-10-22T16:55:57.693680Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encode labels\n",
        "label_to_id = {lab:i for i, lab in enumerate(df_train['label'].sort_values().unique())}\n",
        "id_to_label = {v:k for k,v in label_to_id.items()}\n",
        "label_to_id"
      ],
      "metadata": {
        "id": "HcKn4aXoF3wo",
        "execution": {
          "iopub.status.busy": "2024-10-22T16:55:57.695853Z",
          "iopub.execute_input": "2024-10-22T16:55:57.696173Z",
          "iopub.status.idle": "2024-10-22T16:55:57.722070Z",
          "shell.execute_reply.started": "2024-10-22T16:55:57.696131Z",
          "shell.execute_reply": "2024-10-22T16:55:57.721069Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_out_labels = len(label_to_id)\n",
        "print(\"Number of labels \", num_out_labels)"
      ],
      "metadata": {
        "id": "bfKHoEsfIQkh",
        "execution": {
          "iopub.status.busy": "2024-10-22T16:55:57.726712Z",
          "iopub.execute_input": "2024-10-22T16:55:57.726993Z",
          "iopub.status.idle": "2024-10-22T16:55:57.731939Z",
          "shell.execute_reply.started": "2024-10-22T16:55:57.726962Z",
          "shell.execute_reply": "2024-10-22T16:55:57.730912Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract layers of resnet-50 to build a new model\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchvision.models.resnet import resnet50\n",
        "\n",
        "class ResNetFeatureModel(nn.Module):\n",
        "    def __init__(self, output_layer):\n",
        "        super().__init__()\n",
        "        self.output_layer = output_layer\n",
        "        pretrained_resnet = resnet50(pretrained=True)\n",
        "        self.children_list = []\n",
        "        for n,c in pretrained_resnet.named_children():\n",
        "            self.children_list.append(c)\n",
        "            if n == self.output_layer:\n",
        "                break\n",
        "\n",
        "        self.net = nn.Sequential(*self.children_list)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.net(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "jZS6yB6dFXQC",
        "execution": {
          "iopub.status.busy": "2024-10-22T16:55:57.733164Z",
          "iopub.execute_input": "2024-10-22T16:55:57.733952Z",
          "iopub.status.idle": "2024-10-22T16:55:57.743153Z",
          "shell.execute_reply.started": "2024-10-22T16:55:57.733910Z",
          "shell.execute_reply": "2024-10-22T16:55:57.742271Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class ResNetDataset(Dataset):\n",
        "    def __init__(self, df, label_to_id=None, mode='train', text_field=\"caption\", label_field=\"label\", image_path_field=\"image\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            df (DataFrame): The DataFrame containing your data.\n",
        "            label_to_id (dict): Dictionary for mapping labels to IDs. Set to None for test data.\n",
        "            mode (str): Mode of the dataset. One of ['train', 'test', 'dev'].\n",
        "            text_field (str): Column name for text data.\n",
        "            label_field (str): Column name for label data.\n",
        "            image_path_field (str): Column name for image paths.\n",
        "        \"\"\"\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.label_to_id = label_to_id\n",
        "        self.mode = mode  # Mode can be 'train', 'test', or 'dev'\n",
        "        self.text_field = text_field\n",
        "        self.label_field = label_field\n",
        "        self.image_path_field = image_path_field\n",
        "\n",
        "        # ResNet-50 settings\n",
        "        self.img_size = 224\n",
        "        self.mean, self.std = (\n",
        "            0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)\n",
        "\n",
        "        # Define different transformations based on the mode\n",
        "        self.train_transform_func = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(self.img_size, scale=(0.5, 1.0)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(self.mean, self.std)\n",
        "        ])\n",
        "\n",
        "        self.test_transform_func = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(self.img_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(self.mean, self.std)\n",
        "        ])\n",
        "\n",
        "        self.dev_transform_func = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(self.img_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(self.mean, self.std)\n",
        "        ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Get text data\n",
        "        text = str(self.df.at[index, self.text_field])\n",
        "\n",
        "        # Select the correct image folder based on mode\n",
        "        if self.mode == 'test':\n",
        "            img_path = IMAGE_TEST_FOLDER + self.df.at[index, self.image_path_field]\n",
        "        else:\n",
        "            img_path = IMAGE_TRAIN_FOLDER + self.df.at[index, self.image_path_field]\n",
        "\n",
        "        # Load the image\n",
        "        image = Image.open(img_path).convert('RGB')  # Ensure the image is in RGB format\n",
        "\n",
        "        # Apply appropriate transformations based on mode\n",
        "        if self.mode == 'train':\n",
        "            img = self.train_transform_func(image)\n",
        "        elif self.mode == 'test':\n",
        "            img = self.test_transform_func(image)\n",
        "        elif self.mode == 'dev':\n",
        "            img = self.dev_transform_func(image)\n",
        "\n",
        "        # If labels are available, return them, else only return the image and text\n",
        "        if self.label_to_id is not None and self.label_field in self.df.columns:\n",
        "            label = self.label_to_id[self.df.at[index, self.label_field]]\n",
        "            return text, label, img\n",
        "        else:\n",
        "            return text, img\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n"
      ],
      "metadata": {
        "id": "gqcCN29AFL-t",
        "execution": {
          "iopub.status.busy": "2024-10-22T16:55:57.746340Z",
          "iopub.execute_input": "2024-10-22T16:55:57.746673Z",
          "iopub.status.idle": "2024-10-22T16:55:57.764156Z",
          "shell.execute_reply.started": "2024-10-22T16:55:57.746628Z",
          "shell.execute_reply": "2024-10-22T16:55:57.763412Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "hnUbE_SOFYyb",
        "execution": {
          "iopub.status.busy": "2024-10-22T16:55:57.765396Z",
          "iopub.execute_input": "2024-10-22T16:55:57.765767Z",
          "iopub.status.idle": "2024-10-22T16:55:57.777826Z",
          "shell.execute_reply.started": "2024-10-22T16:55:57.765722Z",
          "shell.execute_reply": "2024-10-22T16:55:57.777000Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VisoBertResNetModel(nn.Module):\n",
        "    def __init__(self, num_labels, text_pretrained='google-bert/bert-base-uncased', mlp_hidden_size=512, dropout_prob=0.3):\n",
        "        super().__init__()\n",
        "        self.text_encoder = AutoModel.from_pretrained(text_pretrained)\n",
        "        self.visual_encoder = ResNetFeatureModel(output_layer='avgpool')\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')\n",
        "        self.image_hidden_size = 2048\n",
        "\n",
        "        # MLP with one hidden layer\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(self.text_encoder.config.hidden_size + self.image_hidden_size, mlp_hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_prob),  # Optional: apply dropout for regularization\n",
        "            nn.Linear(mlp_hidden_size, mlp_hidden_size),  # New hidden layer\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(dropout_prob)  # Optional: apply dropout for the second hidden layer\n",
        "        )\n",
        "\n",
        "        # Classifier\n",
        "\n",
        "        self.classifier = nn.Linear(mlp_hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, text, image):\n",
        "        # Encode text and image\n",
        "        text_output = self.text_encoder(**text)\n",
        "        text_feature = text_output.last_hidden_state[:, 0, :]  # Take the [CLS] token embedding\n",
        "        img_feature = self.visual_encoder(image)  # Extract image features\n",
        "\n",
        "        # Concatenate text and image features\n",
        "        features = torch.cat((text_feature, img_feature), 1)\n",
        "\n",
        "        # Pass through MLP layer\n",
        "        mlp_output = self.mlp(features)\n",
        "\n",
        "        # Classify using the final output of the MLP\n",
        "        logits = self.classifier(mlp_output)\n",
        "\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "xZHp2kC5FZ6v",
        "execution": {
          "iopub.status.busy": "2024-10-22T16:55:57.779036Z",
          "iopub.execute_input": "2024-10-22T16:55:57.779425Z",
          "iopub.status.idle": "2024-10-22T16:55:57.790040Z",
          "shell.execute_reply.started": "2024-10-22T16:55:57.779378Z",
          "shell.execute_reply": "2024-10-22T16:55:57.789182Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Specify the path to the saved model\n",
        "#model_path = \"/kaggle/input/dsc2024/resnet_model_v7.pth\"\n",
        "\n",
        "# Assuming the same model architecture is defined\n",
        "model = VisoBertResNetModel(num_labels=num_out_labels, text_pretrained='google-bert/bert-base-uncased')\n",
        " # Replace `MyModel` with your actual model class\n",
        "\n",
        "# Load the state_dict from the file\n",
        "#model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "# Move the model to the appropriate device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model=model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "#model.train()\n",
        "\n",
        "#print(f\"Model loaded from {model_path}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T16:55:57.791181Z",
          "iopub.execute_input": "2024-10-22T16:55:57.791498Z",
          "iopub.status.idle": "2024-10-22T16:56:02.674778Z",
          "shell.execute_reply.started": "2024-10-22T16:55:57.791467Z",
          "shell.execute_reply": "2024-10-22T16:56:02.673961Z"
        },
        "trusted": true,
        "id": "c9iq3Mrijmqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T16:56:02.675838Z",
          "iopub.execute_input": "2024-10-22T16:56:02.676110Z",
          "iopub.status.idle": "2024-10-22T16:56:02.686325Z",
          "shell.execute_reply.started": "2024-10-22T16:56:02.676081Z",
          "shell.execute_reply": "2024-10-22T16:56:02.685416Z"
        },
        "trusted": true,
        "id": "xEfUup-Njmqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T16:56:02.687637Z",
          "iopub.execute_input": "2024-10-22T16:56:02.687932Z",
          "iopub.status.idle": "2024-10-22T16:56:03.722578Z",
          "shell.execute_reply.started": "2024-10-22T16:56:02.687901Z",
          "shell.execute_reply": "2024-10-22T16:56:03.721389Z"
        },
        "trusted": true,
        "id": "QCSekIrHjmqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "training_params = {\n",
        "    \"seed_val\": seed_val,\n",
        "    \"training_size\" : len(df_train),\n",
        "    \"dev_size\": len(df_dev),\n",
        "    \"test_size\": len(df_test),\n",
        "    \"num_train_epochs\": 20,\n",
        "    \"batch_size\": 64,\n",
        "    \"learning_rate\": 1e-5,\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"warmup_steps\": 10000,\n",
        "    \"max_seq_length\": 64\n",
        "}\n"
      ],
      "metadata": {
        "id": "WlAYOob2Fqqq",
        "execution": {
          "iopub.status.busy": "2024-10-22T16:56:03.724132Z",
          "iopub.execute_input": "2024-10-22T16:56:03.724512Z",
          "iopub.status.idle": "2024-10-22T16:56:03.730179Z",
          "shell.execute_reply.started": "2024-10-22T16:56:03.724475Z",
          "shell.execute_reply": "2024-10-22T16:56:03.729260Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing each value by key\n",
        "seed_val = training_params['seed_val']\n",
        "training_size = training_params['training_size']\n",
        "dev_size = training_params['dev_size']\n",
        "test_size = training_params['test_size']\n",
        "num_train_epochs = training_params['num_train_epochs']\n",
        "batch_size = training_params['batch_size']\n",
        "learning_rate = training_params['learning_rate']\n",
        "weight_decay = training_params['weight_decay']\n",
        "warmup_steps = training_params['warmup_steps']\n",
        "max_seq_length = training_params['max_seq_length']\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T16:56:03.731493Z",
          "iopub.execute_input": "2024-10-22T16:56:03.731836Z",
          "iopub.status.idle": "2024-10-22T16:56:03.741520Z",
          "shell.execute_reply.started": "2024-10-22T16:56:03.731804Z",
          "shell.execute_reply": "2024-10-22T16:56:03.740681Z"
        },
        "trusted": true,
        "id": "YB4HsJw4jmqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_params"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T16:56:03.742604Z",
          "iopub.execute_input": "2024-10-22T16:56:03.742894Z",
          "iopub.status.idle": "2024-10-22T16:56:03.753206Z",
          "shell.execute_reply.started": "2024-10-22T16:56:03.742863Z",
          "shell.execute_reply": "2024-10-22T16:56:03.752259Z"
        },
        "trusted": true,
        "id": "0tRM70Wzjmqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training step\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "from tqdm import trange, tqdm\n",
        "import torch.nn as nn\n",
        "from transformers import get_scheduler, AdamW\n",
        "import time\n",
        "\n",
        "\n",
        "# Set up gradient accumulation steps and use mixed precision\n",
        "accumulation_steps = 4  # Perform backward pass and optimizer step after this many batches\n",
        "scaler = GradScaler()   # For mixed precision\n",
        "\n",
        "train_dataset = ResNetDataset(df=df_train, label_to_id=label_to_id, mode='train', text_field='caption', label_field='label', image_path_field='image')\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "t_total = len(train_dataloader) * num_train_epochs\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "scheduler = get_scheduler(name=\"cosine\", optimizer=optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
        "\n",
        "# Set the device to the second GPU (GPU 1)\n",
        "# Move model to the device\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "start = time.perf_counter()\n",
        "\n",
        "\n",
        "# Initialize lists to store epoch loss and learning rate\n",
        "epoch_losses = []\n",
        "learning_rates = []\n",
        "\n",
        "# Set up training loop with tqdm only for epochs\n",
        "for epoch_num in trange(num_train_epochs, desc='Epochs'):\n",
        "    model.train()  # Set the model to training mode\n",
        "    epoch_total_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_text, b_labels, b_imgs = batch\n",
        "\n",
        "        # Tokenize text input\n",
        "        b_inputs = model.tokenizer(\n",
        "            list(b_text), truncation=True, max_length=max_seq_length,\n",
        "            return_tensors=\"pt\", padding=True\n",
        "        )\n",
        "\n",
        "        # Move labels, images, and inputs to the GPU\n",
        "        b_labels = b_labels.to(device)\n",
        "        b_imgs = b_imgs.to(device)\n",
        "        b_inputs = {k: v.to(device) for k, v in b_inputs.items()}\n",
        "\n",
        "        # Enable mixed precision using autocast\n",
        "        with autocast():\n",
        "            b_logits = model(text=b_inputs, image=b_imgs)  # Forward pass\n",
        "            loss = criterion(b_logits, b_labels)  # Calculate loss\n",
        "\n",
        "        # Accumulate loss for gradient accumulation\n",
        "        loss = loss / accumulation_steps\n",
        "        scaler.scale(loss).backward()  # Scale and backpropagate the loss\n",
        "\n",
        "        # Perform optimizer step after the defined accumulation steps\n",
        "        if (step + 1) % accumulation_steps == 0 or (step + 1) == len(train_dataloader):\n",
        "            scaler.step(optimizer)  # Perform the optimizer step\n",
        "            scaler.update()  # Update the scale for next iteration\n",
        "            optimizer.zero_grad()  # Clear gradients\n",
        "            scheduler.step()  # Update learning rate at the end of each batch\n",
        "\n",
        "        # Accumulate the total loss\n",
        "        epoch_total_loss += loss.item() * accumulation_steps\n",
        "\n",
        "    # Compute average loss for the epoch\n",
        "    avg_loss = epoch_total_loss / len(train_dataloader)\n",
        "\n",
        "    # Save the average loss and learning rate for this epoch\n",
        "    epoch_losses.append(avg_loss)\n",
        "    learning_rates.append(optimizer.param_groups[0]['lr'])\n",
        "    torch.cuda.empty_cache()  # Clear unused cached memory after each epoch\n",
        "\n",
        "\n",
        "    # Print results after each epoch\n",
        "    print(f'Epoch = {epoch_num + 1}')\n",
        "    print(f'    Epoch loss = {epoch_total_loss}')\n",
        "    print(f'    Average epoch loss = {avg_loss}')\n",
        "    print(f'    Learning rate = {optimizer.param_groups[0][\"lr\"]}')\n",
        "\n",
        "end = time.perf_counter()\n",
        "resnet_training_time = end - start\n",
        "print(f'Training completed in {resnet_training_time} seconds')\n",
        "\n",
        "# Plot the loss and learning rate curves\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_train_epochs + 1), epoch_losses, label=\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss per Epoch\")\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot learning rate\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_train_epochs + 1), learning_rates, label=\"Learning Rate\", color='orange')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Learning Rate per Epoch\")\n",
        "plt.grid(True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6ybYsxKeFdaz",
        "execution": {
          "iopub.status.busy": "2024-10-22T16:56:03.754373Z",
          "iopub.execute_input": "2024-10-22T16:56:03.754660Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "trusted": true,
        "id": "3rag70JGjmqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "import torch\n",
        "\n",
        "# Assuming your trained model is called 'model'\n",
        "import os\n",
        "# Path to save the model\n",
        "model_save_path = 'resnet_model_v8.pth'\n",
        "\n",
        "# Save the model's state_dict\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ],
      "metadata": {
        "id": "pxLct_HGqMbg",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing loop\n",
        "\n",
        "resnet_prediction_results = []\n",
        "\n",
        "test_dataset = ResNetDataset(df=df_dev, label_to_id=label_to_id, mode='dev', text_field='caption', label_field='label', image_path_field='image')\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(dataset=test_dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            sampler=test_sampler)\n",
        "\n",
        "\n",
        "for batch in tqdm(test_dataloader):\n",
        "\n",
        "  b_text, b_labels, b_imgs = batch\n",
        "\n",
        "  b_inputs = model.tokenizer(list(b_text), truncation=True, max_length=max_seq_length, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "  b_labels = b_labels.to(device)\n",
        "  b_imgs = b_imgs.to(device)\n",
        "  b_inputs = b_inputs.to(device)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      b_logits = model(text=b_inputs, image=b_imgs)\n",
        "      b_logits = b_logits.detach().cpu()\n",
        "\n",
        "  resnet_prediction_results += torch.argmax(b_logits, dim=-1).tolist()\n",
        "\n",
        "resnet_prediction_labels = [id_to_label[p] for p in resnet_prediction_results]"
      ],
      "metadata": {
        "trusted": true,
        "id": "BYsQek5zjmqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(resnet_prediction_labels)"
      ],
      "metadata": {
        "trusted": true,
        "id": "oA58medqjmqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (len(resnet_prediction_labels) == len(df_dev)):\n",
        "    print(True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "sJEGR6V0jmqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_class_report = classification_report(df_dev['label'], resnet_prediction_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "E-CLXlB0Fg1m",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_class_report"
      ],
      "metadata": {
        "id": "vs3mO292KkiC",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_params['results']=resnet_class_report"
      ],
      "metadata": {
        "trusted": true,
        "id": "koCw1msVjmqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_params"
      ],
      "metadata": {
        "trusted": true,
        "id": "6jqix5QLjmqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the file path\n",
        "file_path = \"/kaggle/working/training_report_v6.txt\"\n",
        "\n",
        "# Format the dictionary as a string\n",
        "report_content = \"\\n\".join([f\"{key}: {value}\" for key, value in training_params.items()])\n",
        "\n",
        "# Save the report to a text file\n",
        "with open(file_path, mode=\"w\") as file:\n",
        "    file.write(report_content)\n",
        "\n",
        "print(f\"Report saved to {file_path}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "SDGlOvFNjmqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eAwbmRgCqMA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making prediction\n"
      ],
      "metadata": {
        "id": "q1onJ8sqjmqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "trusted": true,
        "id": "bbyczZDpjmqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming df_test has columns ['caption', 'image']\n",
        "\n",
        "# Initialize the dataset for the test set (no labels, test transformation)\n",
        "test_dataset = ResNetDataset(\n",
        "    df=df_test,  # DataFrame containing the new data\n",
        "    label_to_id=None,  # No labels for prediction\n",
        "    mode='test',  # Since it's a test dataset, set train=False for evaluation transforms\n",
        "    text_field=\"caption\",  # Column for captions\n",
        "    image_path_field=\"image\"  # Column for image paths\n",
        ")\n",
        "\n",
        "# Set up a DataLoader for the test dataset\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,  # Adjust your batch size as needed\n",
        "    sampler=test_sampler\n",
        ")\n",
        "\n",
        "# Now you can use the test_dataloader in a prediction loop\n",
        "prediction_results = []\n",
        "# Set the model to evaluation mode\n",
        "\n",
        "for batch in tqdm(test_dataloader):\n",
        "    b_text, b_imgs = batch  # No labels are unpacked here\n",
        "\n",
        "    # Tokenize the input text (captions)\n",
        "    b_inputs = model.tokenizer(\n",
        "        list(b_text), truncation=True, max_length=max_seq_length, return_tensors=\"pt\", padding=True\n",
        "    )\n",
        "\n",
        "    # Move inputs to the correct device\n",
        "    b_imgs = b_imgs.to(device)\n",
        "    b_inputs = {k: v.to(device) for k, v in b_inputs.items()}\n",
        "\n",
        "    # Perform inference\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        b_logits = model(text=b_inputs, image=b_imgs)\n",
        "        b_logits = b_logits.detach().cpu()  # Move logits to CPU for further processing\n",
        "\n",
        "    # Collect predictions\n",
        "    prediction_results += torch.argmax(b_logits, dim=-1).tolist()\n",
        "\n",
        "# If you have an id_to_label mapping, convert indices to labels (if needed)\n",
        "if 'id_to_label' in locals():\n",
        "    predicted_labels = [id_to_label[p] for p in prediction_results]\n",
        "else:\n",
        "    predicted_labels = prediction_results  # Return indices if no label mapping exists\n",
        "\n",
        "# Output predictions\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "kkXXZOWHjmqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.sample(5)"
      ],
      "metadata": {
        "trusted": true,
        "id": "yhC_ct88jmqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(len(predicted_labels)==len(df_test)):\n",
        "    print(True)\n",
        "else: print(False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "p2EdLLDZjmqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make submission\n",
        "prediction_results = {\n",
        "    \"results\": {\n",
        "        str(df_test['_key'].iloc[i]): predicted_labels[i] for i in range(len(predicted_labels))  # Map IDs to predicted labels\n",
        "    },\n",
        "    \"phase\": \"dev\"  # Set phase as 'test', 'dev', or 'train' as appropriate\n",
        "}\n",
        "\n",
        "# Print the structured results"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "id": "rXt-3aBijmqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# File path where you want to save the JSON file\n",
        "output_file = \"results3.json\"\n",
        "\n",
        "# Save the dictionary as a JSON file\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(prediction_results, f, indent=4)\n",
        "\n",
        "print(f\"Prediction results saved to {output_file}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "7WEBnmRbjmql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "oXprEtGqjmql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1_GhYHqGjmql"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}